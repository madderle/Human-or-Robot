{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Live Auction Neural Network\n",
    "\n",
    "#### Plan\n",
    "1. Try new method of upsampling, where randomly select features\n",
    "2. Randomized Hyper parameter grid search\n",
    "3. Unsupervised Pre-Training\n",
    "4. MLP\n",
    "5. Compare to other methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## Imports #####################################################\n",
    "\n",
    "# Basic Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Model Infrastructure\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, f_classif\n",
    "from sklearn.utils import resample\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy import stats\n",
    "import random\n",
    "\n",
    "import boto3\n",
    "import io\n",
    "\n",
    "# Models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sknn import ae, mlp\n",
    "from sklearn import ensemble\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Execution time: 24.265435695648193 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#################################### Bring in Data #############################################\n",
    "start_time = time.time()\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "#Bring in Training Data\n",
    "obj = s3.get_object(Bucket='data-science-project-data', Key='Human_or_Robot/train.csv')\n",
    "train = pd.read_csv(io.BytesIO(obj['Body'].read()))\n",
    "train.set_index('bidder_id', inplace=True)\n",
    "\n",
    "# Bring in bids data\n",
    "obj = s3.get_object(Bucket='data-science-project-data', Key='Human_or_Robot/bids.csv')\n",
    "bids = pd.read_csv(io.BytesIO(obj['Body'].read()))\n",
    "\n",
    "print(\"-- Execution time: %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>payment_account</th>\n",
       "      <th>address</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bidder_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91a3c57b13234af24875c56fb7e2b2f4rb56a</th>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228754av</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228vt0u4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624f258b49e77713fc34034560f93fb3hu3jo</th>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228v1sga</td>\n",
       "      <td>ae87054e5a97a8f840a3991d12611fdcrfbq3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1c5f4fc669099bfbfac515cd26997bd12ruaj</th>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c2280cybl</td>\n",
       "      <td>92520288b50f03907041887884ba49c0cl0pd</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4bee9aba2abda51bf43d639013d6efe12iycd</th>\n",
       "      <td>51d80e233f7b6a7dfdee484a3c120f3b2ita8</td>\n",
       "      <td>4cb9717c8ad7e88a9a284989dd79b98dbevyi</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4ab12bc61c82ddd9c2d65e60555808acqgos1</th>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c22857ddh</td>\n",
       "      <td>2a96c3ce94b3be921e0296097b88b56a7x1ji</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             payment_account  \\\n",
       "bidder_id                                                                      \n",
       "91a3c57b13234af24875c56fb7e2b2f4rb56a  a3d2de7675556553a5f08e4c88d2c228754av   \n",
       "624f258b49e77713fc34034560f93fb3hu3jo  a3d2de7675556553a5f08e4c88d2c228v1sga   \n",
       "1c5f4fc669099bfbfac515cd26997bd12ruaj  a3d2de7675556553a5f08e4c88d2c2280cybl   \n",
       "4bee9aba2abda51bf43d639013d6efe12iycd  51d80e233f7b6a7dfdee484a3c120f3b2ita8   \n",
       "4ab12bc61c82ddd9c2d65e60555808acqgos1  a3d2de7675556553a5f08e4c88d2c22857ddh   \n",
       "\n",
       "                                                                     address  \\\n",
       "bidder_id                                                                      \n",
       "91a3c57b13234af24875c56fb7e2b2f4rb56a  a3d2de7675556553a5f08e4c88d2c228vt0u4   \n",
       "624f258b49e77713fc34034560f93fb3hu3jo  ae87054e5a97a8f840a3991d12611fdcrfbq3   \n",
       "1c5f4fc669099bfbfac515cd26997bd12ruaj  92520288b50f03907041887884ba49c0cl0pd   \n",
       "4bee9aba2abda51bf43d639013d6efe12iycd  4cb9717c8ad7e88a9a284989dd79b98dbevyi   \n",
       "4ab12bc61c82ddd9c2d65e60555808acqgos1  2a96c3ce94b3be921e0296097b88b56a7x1ji   \n",
       "\n",
       "                                       outcome  \n",
       "bidder_id                                       \n",
       "91a3c57b13234af24875c56fb7e2b2f4rb56a      0.0  \n",
       "624f258b49e77713fc34034560f93fb3hu3jo      0.0  \n",
       "1c5f4fc669099bfbfac515cd26997bd12ruaj      0.0  \n",
       "4bee9aba2abda51bf43d639013d6efe12iycd      0.0  \n",
       "4ab12bc61c82ddd9c2d65e60555808acqgos1      0.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################### Functions ##############################################\n",
    "\n",
    "#Create function to time into a real time stamp. Assuming min_time_diff is a second.\n",
    "def convert_time(time):\n",
    "    min_time_diff = 52631579\n",
    "    #Time in seconds of 1/1/2010 12:00AM since 1970\n",
    "    init_seconds = 1262347200\n",
    "    #Minimum value from dataset\n",
    "    min_time = 9631916842105263\n",
    "\n",
    "    b = init_seconds - (1/min_time_diff)*min_time\n",
    "    timestamp = (1/min_time_diff)*time + b\n",
    "    return datetime.datetime.fromtimestamp(timestamp)\n",
    "\n",
    "\n",
    "########## Create the bids dataframe ################\n",
    "def create_bid_dataframe(data):\n",
    "    # Create converted Time column\n",
    "    data['Converted Time'] = data['time'].apply(lambda x: convert_time(x))\n",
    "    \n",
    "    # Create bidder aggregation\n",
    "    bidder_aggregate = data.groupby(['bidder_id'])['bid_id'].count().to_frame()\n",
    "    bidder_aggregate.columns = ['Total Bids']\n",
    "    bidder_aggregate['Total Auctions'] = data.groupby(['bidder_id'])['auction'].nunique()\n",
    "    bidder_aggregate['Number of Merchandise'] = data.groupby(['bidder_id'])['merchandise'].nunique()\n",
    "    bidder_aggregate['Number of Device'] = data.groupby(['bidder_id'])['device'].nunique()\n",
    "    bidder_aggregate['Number of IPs'] = data.groupby(['bidder_id'])['ip'].nunique()\n",
    "    bidder_aggregate['Number of URLs'] = data.groupby(['bidder_id'])['url'].nunique()\n",
    "    bidder_aggregate['Number of Countries'] = data.groupby(['bidder_id'])['country'].nunique()\n",
    "    bidder_aggregate['Number of Bids IN'] = bids[bids['country']=='in'].groupby(['bidder_id'])['country'].count()\n",
    "    bidder_aggregate['Number of Bids NG'] = bids[bids['country']=='ng'].groupby(['bidder_id'])['country'].count()\n",
    "    bidder_aggregate['Number of Bids ID'] = bids[bids['country']=='id'].groupby(['bidder_id'])['country'].count()\n",
    "    bidder_aggregate['Number of Bids TR'] = bids[bids['country']=='tr'].groupby(['bidder_id'])['country'].count()\n",
    "    bidder_aggregate['Number of Bids US'] = bids[bids['country']=='us'].groupby(['bidder_id'])['country'].count()\n",
    "    bidder_aggregate.fillna(0, inplace=True)\n",
    "    \n",
    "    # Create Bidder Auction Dataframe\n",
    "    bidder_auction = data.groupby(['bidder_id','auction'])['Converted Time'].min().to_frame()\n",
    "    bidder_auction.columns = ['First Bid Time']\n",
    "    bidder_auction['Last Bid Time'] = data.groupby(['bidder_id','auction'])['Converted Time'].max()\n",
    "    bidder_auction['Bid Time Difference'] = bidder_auction['Last Bid Time'] - bidder_auction['First Bid Time']\n",
    "    bidder_auction['Number of Bids'] = data.groupby(['bidder_id','auction'])['time'].count()\n",
    "    bidder_auction['Mean Time per Bid'] = bidder_auction['Bid Time Difference']/bidder_auction['Number of Bids']\n",
    "    \n",
    "    # Creat Auction Dataframe\n",
    "    auction = data.groupby(['auction'])['Converted Time'].min().to_frame()\n",
    "    auction.columns = ['Auction Started']\n",
    "    auction['Auction Ended'] = data.groupby(['auction'])['Converted Time'].max()\n",
    "    auction['Auction Time Difference'] = auction['Auction Ended'] - auction['Auction Started']\n",
    "    auction['Number of Bidders'] = data.groupby(['auction'])['bidder_id'].nunique()\n",
    "    \n",
    "    # Join Auction with Bidder_auction\n",
    "    bidder_auction_full = bidder_auction.join(auction, how='inner')\n",
    "    #Particpation measure. How much of the auction particpated in (time)\n",
    "    bidder_auction_full['Time Particpation'] = (((bidder_auction_full['Auction Ended'] \n",
    "                                                 - bidder_auction_full['First Bid Time'])/bidder_auction_full['Auction Time Difference']))*100\n",
    "    # Started ratio (When got in the higher the number the later)\n",
    "    bidder_auction_full['Started Ratio'] = (((bidder_auction_full['First Bid Time'] \n",
    "                                                     - bidder_auction_full['Auction Started'])/bidder_auction_full['Auction Time Difference']))*100\n",
    "    # Won Auction\n",
    "    bidder_auction_full['Won Auction'] = bidder_auction_full['Last Bid Time']==bidder_auction_full['Auction Ended']\n",
    "    \n",
    "    # Now time to aggregate\n",
    "    bidder_auction_full_aggregate = bidder_auction_full.groupby(['bidder_id'])['Mean Time per Bid'].min().to_frame()\n",
    "    bidder_auction_full_aggregate.columns = ['Min Mean Time per Bid']\n",
    "    bidder_auction_full_aggregate['Max Mean Time per Bid'] = bidder_auction_full.groupby(['bidder_id'])['Mean Time per Bid'].max()\n",
    "    bidder_auction_full_aggregate['Min Time Particpation'] = bidder_auction_full.groupby(['bidder_id'])['Time Particpation'].min()\n",
    "    bidder_auction_full_aggregate['Max Time Particpation'] = bidder_auction_full.groupby(['bidder_id'])['Time Particpation'].max()\n",
    "    bidder_auction_full_aggregate['Mean Time Particpation'] = bidder_auction_full.groupby(['bidder_id'])['Time Particpation'].mean()\n",
    "    bidder_auction_full_aggregate['Min Started Ratio'] = bidder_auction_full.groupby(['bidder_id'])['Started Ratio'].min().to_frame()\n",
    "    bidder_auction_full_aggregate['Max Started Ratio'] = bidder_auction_full.groupby(['bidder_id'])['Started Ratio'].max().to_frame()\n",
    "    bidder_auction_full_aggregate['Mean Started Ratio'] = bidder_auction_full.groupby(['bidder_id'])['Started Ratio'].mean().to_frame()\n",
    "    bidder_auction_full_aggregate['Auctions Won'] = bidder_auction_full[bidder_auction_full['Won Auction']==True].groupby(['bidder_id'])['Won Auction'].count()\n",
    "    bidder_auction_full_aggregate.fillna(0, inplace=True)\n",
    "    \n",
    "    # Joing to bidder aggregate\n",
    "    bidder_features = bidder_aggregate.join(bidder_auction_full_aggregate, how='inner')\n",
    "    \n",
    "    #Convert Time Delta to seconds\n",
    "    bidder_features['Max Mean Time per Bid'] = bidder_features['Max Mean Time per Bid'].apply(lambda x: x.total_seconds())\n",
    "    bidder_features['Min Mean Time per Bid'] = bidder_features['Min Mean Time per Bid'].apply(lambda x: x.total_seconds())\n",
    "    \n",
    "    return bidder_features\n",
    "    \n",
    "\n",
    "############### Join the bidder_feature ##################\n",
    "\n",
    "def add_features(train, features):\n",
    "    return train.join(features, how='inner')\n",
    "\n",
    "\n",
    "################# Custom Shuffle ########################\n",
    "def custom_shuffle(df, n):\n",
    "    columns = df.columns.tolist()\n",
    "    length = len(df) - 1\n",
    "    output = []\n",
    "    for _ in range (n):\n",
    "        row = {}\n",
    "        for column in columns:\n",
    "            index = random.randint(0,length)\n",
    "            # Select random value\n",
    "            row[column] = df[column][index]\n",
    "        output.append(row)\n",
    "    return pd.DataFrame(output)\n",
    "\n",
    "\n",
    "################# Data Split #############################\n",
    "'''\n",
    "train - the training data set\n",
    "split_percent - the train/test split\n",
    "minority_upsample_percent - the percent to upsample by\n",
    "'''\n",
    "def train_split(train, split_percent, minority_upsample_percent):\n",
    "    # Create initial x and y\n",
    "    y = train['outcome']\n",
    "    X = train.drop(['payment_account','address'],1)\n",
    "\n",
    "    # Split the Data \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=split_percent)\n",
    "\n",
    "    # Drop outcome from X_test\n",
    "    X_test = X_test.drop(['outcome'],1)\n",
    "\n",
    "    # Do the upsample on the X_train\n",
    "    df_majority = X_train[X_train.outcome==0]\n",
    "    df_minority = X_train[X_train.outcome==1]\n",
    "    \n",
    "    # Calculate Upsample Percent\n",
    "    nsamples = int(len(df_minority) + len(df_minority)*minority_upsample_percent)\n",
    "    \n",
    "    # Upsample minority class\n",
    "    df_minority_upsampled = resample(df_minority, \n",
    "                                     replace=True,     # sample with replacement\n",
    "                                     n_samples=nsamples,    # to match majority class\n",
    "                                     random_state=123) # reproducible results \n",
    "\n",
    "    # Combine majority class with upsampled minority class\n",
    "    df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "\n",
    "    # Rename the X_train and y_train\n",
    "    X_train = df_upsampled.drop(['outcome'],1)\n",
    "    y_train = df_upsampled['outcome']\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "######### Separate Outcome feature split ########################\n",
    "def outcome_feature_split(train):\n",
    "    y = train['outcome']\n",
    "    X = train.drop(['outcome','payment_account','address'],1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Execution time: 109.03289484977722 seconds ---\n"
     ]
    }
   ],
   "source": [
    "###################### Assemble Data ########################################\n",
    "start_time = time.time()\n",
    "\n",
    "# Create Bidder Features\n",
    "bids.dropna(inplace=True)\n",
    "bidder_features = create_bid_dataframe(bids)\n",
    "\n",
    "#Create Training Set\n",
    "training_set = add_features(train, bidder_features)\n",
    "\n",
    "print(\"-- Execution time: %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Test train split\n",
    "X_train, X_test, y_train, y_test = train_split(training_set, 0.3, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 6.471538782119751 seconds ---\n",
      "0.9390973794888385\n"
     ]
    }
   ],
   "source": [
    "####################### Gradient Boost Model ################################################\n",
    "\n",
    "#Will use Grid Search to do the cross validation.\n",
    "start_time = time.time()\n",
    "parameters = {'subsample':[0.95],\n",
    "              'max_depth':[2],\n",
    "             'n_estimators':[500]}\n",
    "\n",
    "# Initialize the model.\n",
    "clf = ensemble.GradientBoostingClassifier(max_depth=6,loss='exponential')\n",
    "\n",
    "#Create grid and perform 8 cross validation\n",
    "gradient_grid = GridSearchCV(clf, parameters, cv=8, verbose=0, scoring='roc_auc')\n",
    "\n",
    "#Fit the Data\n",
    "gradient_grid.fit(X_train, y_train)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "\n",
    "#  Test Score\n",
    "gradient_prediction = gradient_grid.predict(X_test)\n",
    "\n",
    "gradient_prediction_proba = gradient_grid.predict_proba(X_test)\n",
    "gradient_prediction_proba = [p[1] for p in gradient_prediction_proba]\n",
    "\n",
    "# Produce the AUROC\n",
    "print(roc_auc_score(y_test, gradient_prediction_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.96      0.99      0.97       562\n",
      "        1.0       0.64      0.21      0.32        33\n",
      "\n",
      "avg / total       0.94      0.95      0.94       595\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tree based models do better with unbalanced classes.\n",
    "print(classification_report(y_test, gradient_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8793809985980805\n",
      "-- Execution time: 199.10712671279907 seconds ---\n"
     ]
    }
   ],
   "source": [
    "################## MLP Model #################################################################\n",
    "start_time = time.time()\n",
    "# Establish and fit the model, with a single, 1000 perceptron layer.\n",
    "\n",
    "parameters = {'hidden_layer_sizes':[(1000,1000)],\n",
    "             'activation':['logistic'],\n",
    "             'solver':['adam'],\n",
    "             'alpha':[0.0001, 0.001, 0.01, 1, 10, 100]}\n",
    "\n",
    "mlp = MLPClassifier()\n",
    "\n",
    "mlp_grid = GridSearchCV(mlp, parameters, scoring='roc_auc', cv=5, verbose=0)\n",
    "\n",
    "mlp_grid.fit(X_train, y_train)\n",
    "\n",
    "mlp_prediction_proba = mlp_grid.predict_proba(X_test)\n",
    "mlp_prediction_proba = [p[1] for p in mlp_prediction_proba]\n",
    "\n",
    "# Produce the AUROC\n",
    "print(roc_auc_score(y_test, mlp_prediction_proba))\n",
    "print(\"-- Execution time: %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'logistic',\n",
       " 'alpha': 0.01,\n",
       " 'hidden_layer_sizes': (1000, 1000),\n",
       " 'solver': 'adam'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      1.00      0.97       562\n",
      "        1.0       0.50      0.06      0.11        33\n",
      "\n",
      "avg / total       0.92      0.94      0.92       595\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MLP really doesnt do well with unbalanced classes.\n",
    "mlp_prediction = mlp_grid.predict(X_test)\n",
    "print(classification_report(y_test, mlp_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
